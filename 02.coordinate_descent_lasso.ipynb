{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso Regression and Coordinate Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "I am going to give some short analysis on lasso regression and implement the coordinate descent method to solve lasso regression. For experimental purpose, a small dataset with known parameters will be constructed that helps explain why L-1 regularization leads to sparsity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Data generation\n",
    "\n",
    "We want to create a design matrix for regression, the size of this dataset is 150, each has 75 features. We will choose a true weight vector $\\theta$ such that each sample only has 10 non-zero components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "# 1. Design matrix X \n",
    "X = numpy.random.rand(150,75)\n",
    "\n",
    "# 2. Weight vector theta.\n",
    "#    Set the first 10 component of theta to 10 or -10 arbitrarily and all the other components to zero.\n",
    "t = [-1,1]\n",
    "theta_1 = numpy.random.choice(t,10)*10\n",
    "theta_2 = numpy.zeros(65)\n",
    "theta = numpy.concatenate((theta_1,theta_2), axis=0)\n",
    "\n",
    "# 3. Construct a vector y = X theta + epsilon, where epsilon is a random noise vector\n",
    "epsilon = 0.1*numpy.random.randn(150)\n",
    "y = numpy.dot(X,theta)+epsilon\n",
    "\n",
    "# 4. Split the dataset into training/validation/test set\n",
    "X_train = X[0:80,:]\n",
    "y_train = y[0:80]\n",
    "X_valid = X[80:100,:]\n",
    "y_valid = y[80:100]\n",
    "X_test = X[100:150,:]\n",
    "y_test = y[100:150] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By construction, we know that our dataset admits a sparse solution. \n",
    "\n",
    "First, let's run ridge regression first on our dataset and see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def ridge(X, y, Lambda):\n",
    "    (N,D) = X.shape\n",
    "    def ridge_obj(theta):\n",
    "        return ((np.linalg.norm(np.dot(X, theta) - y))**2)/(2*N) + Lambda*(np.linalg.norm(theta))**2\n",
    "    return ridge_obj\n",
    "\n",
    "\n",
    "def compute_loss(X, y, Lambda, theta):\n",
    "    (N,D) = X.shape\n",
    "    return ((np.linalg.norm(np.dot(X, theta) - y))**2)/(2*N)\n",
    "\n",
    "\n",
    "def optimize_ridge_reg_parameter(X_train, y_train, X_test, y_test):\n",
    "    (N,D) = X_train.shape\n",
    "    min_loss = np.inf\n",
    "    min_loss_lambda = np.inf\n",
    "    min_loss_w = np.zeros((D,1))\n",
    "    losses = []\n",
    "    sparsity = []\n",
    "    lambdas = [pow(10, i) for i in range(-10, 7)]\n",
    "    for Lambda in lambdas:\n",
    "        w = np.random.rand(D,1)\n",
    "        w_opt = minimize(ridge(X_train, y_train, Lambda), w)\n",
    "        loss = compute_loss(X_test, y_test, Lambda, w_opt.x)\n",
    "        losses.append(loss)\n",
    "        sparsity.append(compute_sparsity(w_opt.x))\n",
    "    return losses, sparsity\n",
    "    \n",
    "def feature_normalization(train, test):\n",
    "    # Get the stats\n",
    "    train_max = train.max(axis=0)\n",
    "    train_min = train.min(axis=0)\n",
    "    \n",
    "    # Delete the features that have constant value\n",
    "    equal_indicator = (train_max != train_min)\n",
    "    train = train[:, equal_indicator]\n",
    "    test = test[:, equal_indicator]\n",
    "    train_max = train_max[equal_indicator]\n",
    "    train_min = train_min[equal_indicator]\n",
    "    \n",
    "    # Normalize \n",
    "    train_normalized = (train - train_min) / (train_max - train_min)\n",
    "    test_normalized = (test - train_min) / (train_max - train_min)\n",
    "    \n",
    "    return train_normalized, test_normalized\n",
    "\n",
    "def compute_sparsity(w_opt):\n",
    "    c1 = sum(np.abs(w_opt) < pow(10, -3))\n",
    "    c2 = sum(np.abs(w_opt) < pow(10, -2))\n",
    "    c3 = sum(np.abs(w_opt) < pow(10, -1))\n",
    "    return [c1, c2, c3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid = feature_normalization(X_train, X_valid)\n",
    "losses, spa = optimize_ridge_reg_parameter(X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAHX1JREFUeJzt3XmYnHWZ7vHv3Z2F0NkIaUI2SAKBQFgChCACgqKCwLCv\nKsMIiiAKjsscFh31HBm5xGU8sihHUEY22YlsssPAyBIwITtkJelsnQBJZ+uku57zR70dilBJOqGr\n3lruz3X11VW/et+qJ01Rd73vU/X7KSIwMzPbWE3aBZiZWWlyQJiZWV4OCDMzy8sBYWZmeTkgzMws\nLweEmZnl5YAwM7O8HBBmZpaXA8LMzPLqlHYBH0ffvn1jyJAhaZdhZlZWXn/99aURUb+l7co6IIYM\nGcK4cePSLsPMrKxImtue7XyKyczM8nJAmJlZXg4IMzPLywFhZmZ5OSDMzCwvB4SZmeXlgDAzs7zK\n+nsQZmaFsr41Q8N7a2ha20JLJkNrJmjJxIbfmQ3XMx+Mt0bOdh/dp22J57aVnnMXfP5gLPKMfXTD\nPXbuwQn7DSjMPz7hgDCzqhURNK5sZlbjKmYvzf7MalzJrKWreGfZaloyseU7SYEEJ+w3wAFhZvZx\nrWpuyb74L13F7MZVzFq6MhsIjatoam7ZsF2XTjUM3bGOPXbqwbEjd2ZI3zr6bN+F2lrRqUbUStTW\niE61oramJjtWo5zfNdTW5mxXow371iRjbdouSfnGPqg99/Zic0CYWUWZsmAF/zNz6YfCYPGK5g23\nSzCgVzeG1ddx6oEDGdq3jmH13Rnat44Bvbt96EW82jkgzKxivDn/fU6/8e+sa83Qe/vODOtbx+G7\n1zOsvo5hfesYWl/HkB3r2K5zbdqllgUHhJlVhOWr1/ON29+gb/cu3HvxJxnQu1vaJZU9B4SZlb1M\nJvjO3eNZvGItd3/9UIdDB/H3IMys7P3+hVk8PW0JVx23FwfsskPa5VQMB4SZlbWXZy3jF09M5/h9\n+3PeJ4ekXU5FcUCYWdla0rSWb935D3btsz3XnLZvqh8JrUTuQZhZWWppzXDZneNpWrueP18whh7b\ndU67pIrjgDCzsvTrp97i77OW8Ysz9mfEzj3TLqci+RSTmZWdZ6Yt5vpnZ3LW6MGcftCgtMupWA4I\nMysr899bzb/+ZQJ79e/JT04amXY5Fc0BYWZlo7mllUvu+AeZTHDjlw70N6ILzD0IMysb//HIVCbM\ne5/ffflAhvStS7uciucjCDMrC3+dsIBb/z6XCw4fyrH79E+7nKrggDCzkjezcSWX3/cmB+26A5d/\nYUTa5VQNB4SZlbTV61q4+LbX6dq5luu+eACda/2yVSzuQZhZyYoIfvDgJN5espJbvzKG/r08CV8x\nOYrNrGT95bV53P9GA5d+Zjif2qM+7XKqTsECQtJgSc9KmiJpsqTLkvE+kp6U9Hbye4ecfa6QNEPS\ndEnHFKo2Myt9kxqW8+9jJ3PE8L5cevTwtMupSoU8gmgBvhsRewOfAC6RtDdwOfB0RAwHnk6uk9x2\nNjASOBa4QZI/5GxWhZavWc8ld7xBn+278J9njfIyoCkpWEBExMKIeCO53ARMBQYCJwG3JpvdCpyc\nXD4JuCsimiNiNjADGFOo+sysNEUE379nAg3vreG6Lx7Ajt27pl1S1SpKD0LSEOAA4BWgX0QsTG5a\nBPRLLg8E5uXsNj8ZM7MqcvOLs3liymIu/8IIRg/pk3Y5Va3gASGpO3Af8O2IWJF7W0QEEFt5fxdK\nGidpXGNjYwdWamZpGzfnXX722DSOGdmPCw4fmnY5Va+gASGpM9lwuD0i7k+GF0vqn9zeH1iSjDcA\ng3N2H5SMfUhE3BQRoyNidH29P9VgVimWrmzmm3f8g0E7dOPaM/b34j8loJCfYhJwMzA1In6Vc9NY\n4Lzk8nnAQznjZ0vqKmkoMBx4tVD1mVnpaM0E375rPO+uXscNXzqQnl78pyQU8otyhwHnAhMljU/G\nrgSuAe6WdAEwFzgTICImS7obmEL2E1CXRERrAeszsxLx22fe5sUZS7nm1H0ZOaBX2uVYomABEREv\nAps6Rjx6E/tcDVxdqJrMrPSsb81w43MzOX7f/px18OAt72BF429Sm1mq3lrcRHNLhmP22dl9hxLj\ngDCzVE1qWA7AvgN9aqnUOCDMLFUTG5bTo2sndu2zfdql2EYcEGaWqokNKxg5sCc1nk6j5DggzCw1\n61szTF24gv0G9U67FMvDAWFmqXlrcRPrWjLs4/5DSXJAmFlq3KAubQ4IM0uNG9SlzQFhZqlxg7q0\nOSDMLBVuUJc+B4SZpcIN6tLngDCzVLhBXfocEGaWCjeoS58DwsxS4QZ16XNAmFnRuUFdHhwQZlZ0\nblCXBweEmRWdG9TlwQFhZkXnBnV5cECYWdG5QV0eHBBmVlRuUJcPB4SZFZUb1OXDAWFmReUGdflw\nQJhZUblBXT4cEGZWVG5Qlw8HhJkVjRvU5cUBYWZF4wZ1eXFAmFnRuEFdXhwQZlY0blCXFweEmRWN\nG9TlxQFhZkXhBnX5cUCYWVG4QV1+HBBmVhRuUJcfB4SZFYUb1OXHAWFmReEGdflxQJhZwblBXZ4K\nFhCSbpG0RNKknLEfS2qQND75OS7ntiskzZA0XdIxharLzIrPDeryVMgjiD8Bx+YZ/3VEjEp+HgWQ\ntDdwNjAy2ecGSbUFrM3MisgN6vJUsICIiBeAd9u5+UnAXRHRHBGzgRnAmELVZmbF5QZ1eUqjB/Et\nSW8mp6B2SMYGAvNytpmfjH2EpAsljZM0rrGxsdC1mlkHcIO6PBU7IG4EhgGjgIXAL7f2DiLipogY\nHRGj6+vrO7o+M+tgblCXr6IGREQsjojWiMgA/48PTiM1AINzNh2UjJlZmXODunwVNSAk9c+5egrQ\n9gmnscDZkrpKGgoMB14tZm1mVhhuUJevToW6Y0l3AkcBfSXNB34EHCVpFBDAHODrABExWdLdwBSg\nBbgkIloLVZuZFY8b1OWrYAEREefkGb55M9tfDVxdqHrMLB1uUJcvf5PazArGDery5oAws4Jxg7q8\nOSDMrGDcoC5vDggzKxg3qMubA8LMCmbi/OVuUJcxB4SZFcT61gxTFzW5QV3GHBBmVhBuUJc/B4SZ\nFYQb1OXPAWFmBeEGdflzQJhZQbhBXf4cEGbW4dygrgwOCDPrcG5QVwYHhJl1ODeoK4MDwsw6nBvU\nlcEBYWYdzg3qyuCAMLMO5QZ15XBAmFmHcoO6cjggzKxDuUFdORwQZtah3KCuHO0KCEmXSeqprJsl\nvSHp84UuzszKjxvUlaO9RxDnR8QK4PPADsC5wDUFq8rMypIb1JWlvQHR9lbgOODPETE5Z8zMDHCD\nutK0NyBel/QE2YD4m6QeQKZwZZlZOXKDurJ0aud2FwCjgFkRsVpSH+ArhSvLzMqRG9SVpb1HEIcC\n0yPifUlfBn4ALC9cWWZWjtygriztDYgbgdWS9ge+C8wE/qtgVZlZ2XGDuvK0NyBaIiKAk4DrIuJ6\noEfhyjKzcuMGdeVpbw+iSdIVZD/eeoSkGqBz4coys3LjBnXlae8RxFlAM9nvQywCBgHXFqwqMys7\nb853g7rStCsgklC4Hegl6QRgbUS4B2FmG0xqcIO60rR3qo0zgVeBM4AzgVcknV7IwsysfLhBXZna\n24O4Cjg4IpYASKoHngLuLVRhZlY+3KCuTO3tQdS0hUNi2Vbsa2YVzg3qytTeI4jHJf0NuDO5fhbw\naGFKMrNy4wZ1ZWpvk/r7wE3AfsnPTRHxvza3j6RbJC2RNClnrI+kJyW9nfzeIee2KyTNkDRd0jHb\n9s8xszS4QV2Z2n2aKCLui4jvJD8PtGOXPwHHbjR2OfB0RAwHnk6uI2lv4GxgZLLPDZJq21ubmaXH\nDerKtdmAkNQkaUWenyZJKza3b0S8ALy70fBJwK3J5VuBk3PG74qI5oiYDcwAxmz1v8bMis4N6sq1\n2R5ERHT0dBr9ImJhcnkR0C+5PBB4OWe7+cmYmZU4N6grV2qfRErmdoqt3U/ShZLGSRrX2NhYgMrM\nbGu4QV25ih0QiyX1B0h+t310tgEYnLPdoGTsIyLipogYHRGj6+vrC1qsmW2ZG9SVq9gBMRY4L7l8\nHvBQzvjZkrpKGgoMJ/vNbTMrYW5QV7b2fg9iq0m6EzgK6CtpPvAj4BrgbkkXAHPJTttBREyWdDcw\nBWgBLomI1kLVZmYdww3qylawgIiIczZx09Gb2P5q4OpC1WNmHc8N6srm6TLMbJu5QV3ZHBBmts3c\noK5sDggz2yZuUFc+B4SZbRM3qCufA8LMtokb1JXPAWFm28QN6srngDCzbeIGdeVzQJjZVluyYi1T\nFq5g1OAdtryxlS0HhJlttZtfnE1rJjhnzOAtb2xlywFhZltl+er13PbyXI7fbwC77liXdjlWQA4I\nM9sqf355DqvWtXLRkcPSLsUKzAFhZu22Zl0rf3xpDkftWc/IAf54a6VzQJhZu93z+jyWrVrHxUfu\nlnYpVgQOCDNrl/WtGX7//CwO2nUHxgztk3Y5VgQOCDNrl4ffXEDD+2u4+MjdkPzdh2rggDCzLcpk\nghufm8ke/brzmRE7pV2OFYkDwsy26JlpS3hr8UouPmo3f3O6ijggzGyzIoIbnpvBwN7dOGG/AWmX\nY0XkgDCzzXp19ru88c77fP3IYXSu9UtGNfF/bTPbrBufn8mOdV044yBPq1FtHBBmtklTFqzguemN\nfOWwIXTrUpt2OVZkDggz26Qbn59J966dOPfQIWmXYilwQJhZXnOXreKRNxfwpUN2oVe3zmmXYylw\nQJhZXr9/YRadamo4//ChaZdiKXFAmNlHLFmxlnvHzee0gwbRr+d2aZdjKXFAmNlH3PLSHFoyGb7+\nKU/pXc0cEGb2IcvXZBcEOm7f/gzp6wWBqpkDwsw+5LaX57KyuYWLPKV31XNAmNkGa9e38seXZvOp\nPerZZ6AXBKp2Dggz2+CecfNYunId3zjKRw/mgDCzREtrht+/MIsDdunNIV4QyHBAmFni4TcXMv+9\nNXzjqN29IJABDggzIzul943PzWT4Tt052gsCWcIBYWY8O30J0xc3cdGRXhDIPuCAMDNueHYmA3t3\n48RRXhDIPpBKQEiaI2mipPGSxiVjfSQ9Kent5PcOadRmVm1em/Mu4+a+x9eOGOoFgexD0nw2fDoi\nRkXE6OT65cDTETEceDq5bmYFdsOzM+hT14WzDt4l7VKsxJTS24WTgFuTy7cCJ6dYi1lVmLpwBc9O\nb+Qrn/SCQPZRaQVEAE9Jel3ShclYv4hYmFxeBPTLt6OkCyWNkzSusbGxGLWaVazfPT+Tui61/LMX\nBLI8OqX0uIdHRIOknYAnJU3LvTEiQlLk2zEibgJuAhg9enTebcxsy95Ztpq/TljAV48YRq/tvSCQ\nfVQqRxAR0ZD8XgI8AIwBFkvqD5D8XpJGbWbV4qb/nkmnmhou8IJAtglFDwhJdZJ6tF0GPg9MAsYC\n5yWbnQc8VOzazKpFY1Mzd4+bz6kHDvSCQLZJaZxi6gc8kHyVvxNwR0Q8Luk14G5JFwBzgTNTqM2s\nKtzy0mzWt2b4uqf0ts0oekBExCxg/zzjy4Cji12PWbVZsXY9t/19Lsft05+hXhDINqOUPuZqZkVw\n28tzaWpu4WJP6W1b4IAwqyJr17dyy4tzOGJ4Xy8IZFvkgDCrIve+Pp+lK5t99GDt4oAwqxLj573P\ndc/MYNTg3hw6bMe0y7EykNYX5cysSJrWrueXT7zFrX+fw049uvKjf9rbCwJZuzggzCrY45MW8eOx\nk1nctJZ//sSufO+YPemxnb81be3jgDCrQAveX8OPxk7mySmL2at/T3537kGMGtw77bKszDggzCpI\naya49X/m8MsnptMawRVfGMH5h3udB9s2DgizCjGpYTlXPjCRN+cv58g96vnpyfswuM/2aZdlZcwB\nYVbmVjW38Osn3+KWl2bTp64rvz3nAE7Yr78b0faxOSDMytgz0xbzwwcn0/D+Gs4ZswuXHzvCU3db\nh3FAmJWhJSvW8pO/TuGRiQsZvlN37rnoUA4e0iftsqzCOCDMykgmE9z+6jv8/LFpNLdm+N7n9+DC\nT+1Gl05uQlvHc0CYlYnpi5q44v43eeOd9/nkbjty9Sn7ejZWKygHhFmJW7u+lf/79Nvc9MIsenbr\nzK/O3J9TDhjoJrQVnAPCrIS98FYjP3hwEu+8u5rTDxrElcftRZ+6LmmXZVXCAWFWghqbmvnpI1N4\naPwChvWt446vHcInd+ubdllWZRwQZiUkkwn+Mm4eP3t0KmvXZ7js6OFcfNRubNe5Nu3SrAo5IMxK\nxNuLm7jygYm8Nuc9Dhnah6tP2Zfdd+qedllWxRwQZilbu76V656Zwe9fmEld105ce/p+nH7QIDeh\nLXUOCLMUvfj2Uq56cCJzl63mtAMHceVxI9ixe9e0yzIDHBBmqVi6spmfPjyFB8cvYGjfOu746iF8\ncnc3oa20OCDMiiiTCe4eN4+fPTaN1etauPTo4XzDTWgrUQ4IsyJ5e3ETVz0wiVfnvMuYoX34j1P2\nYfedeqRdltkmOSDMCmzt+lauf3YGv3s+24T++WnZJnRNjZvQVtocEGYF9NKMpVz1wETmLFvNqQcM\n5Krj93IT2sqGA8KsAJatbObqR6Zy/z8aGLLj9tz+1UM4zE1oKzMOCLMOsr41w0szljJ2/AL+NnkR\n61ozXPqZ3fnGp3d3E9rKkgPC7GPIZILX33mPh8Y38OjERby7ah09tuvE8fv152tHDGN4PzehrXw5\nIMy2UkQwecEK/jphAX+dsIAFy9eyXecajt6rHyftP4Aj96ynaycfMVj5c0CYtdPspasYO34BYyc0\nMLNxFZ1qxBHD+/L9Y/fkc3vvTPeu/t/JKouf0WabsWj5Wh5+cwFjJyzgzfnLARgztA/nHz6UL+zT\n32szWEVzQJht5L1V63hs0iLGTmjgldnvEgH7DOzJVcftxQn796d/r25pl2hWFA4Iq3rrWjLMWrqS\nSQ0reGziQp5/q5GWTDCsvo7Ljh7OifsPYFi9p9226lNyASHpWOA3QC3wh4i4JuWSrEJEBItXNDN1\n0QqmL2pi2sIVTFvUxMzGlaxvDQB27rkd5x8+lBP3H8DIAT095bZVtZIKCEm1wPXA54D5wGuSxkbE\nlHQrs3KzqrmF6YubPhQE0xY1sXzN+g3bDOi1HXvu3INPj9iJETv3YMTOPRm+U3dPgWGWKKmAAMYA\nMyJiFoCku4CTAAeE5dWaCeYuW5UNgJwgeOfd1Ru2qetSy5479+D4/fpvCII9+/Wg1/adU6zcrPSV\nWkAMBOblXJ8PHNLRDzJt0Qouuf2Njr5bS7TntExEEAGtEWQiyGSyY5kgez3argetmey2mZzb2663\nJpcBagRD+9ax78BenHHQIPbcuQd79e/JwN7dfFRgtg1KLSC2SNKFwIUAu+yyyzbdR7fOtYzo37Mj\ny7I20Z5NAknUSNQIaqXkOtmxGj58XULJdjU12cu5+w7us3329FC/7p7SwqwDlVpANACDc64PSsY2\niIibgJsARo8e3Y6Xo4/adcc6rv/igdtao5lZVahJu4CNvAYMlzRUUhfgbGBsyjWZmVWlkjqCiIgW\nSd8E/kb2Y663RMTklMsyM6tKJRUQABHxKPBo2nWYmVW7UjvFZGZmJcIBYWZmeTkgzMwsLweEmZnl\n5YAwM7O8FLFN3zUrCZIagbkf4y76Aks7qJyO5Lq2juvaOq5r61RiXbtGRP2WNirrgPi4JI2LiNFp\n17Ex17V1XNfWcV1bp5rr8ikmMzPLywFhZmZ5VXtA3JR2AZvguraO69o6rmvrVG1dVd2DMDOzTav2\nIwgzM9uEqgsISWdImiwpI2n0RrddIWmGpOmSjkmxxlGSXpY0XtI4SWPSqmVjkr4laVryN/x52vXk\nkvRdSSGpb9q1AEi6NvlbvSnpAUm9U67n2OS5PUPS5WnW0kbSYEnPSpqSPKcuS7umXJJqJf1D0sNp\n19JGUm9J9ybPramSDi3UY1VdQACTgFOBF3IHJe1Ndv2JkcCxwA2S0lqe7OfATyJiFPDvyfXUSfo0\n2TXC94+IkcAvUi5pA0mDgc8D76RdS44ngX0iYj/gLeCKtApJnsvXA18A9gbOSZ7zaWsBvhsRewOf\nAC4pkbraXAZMTbuIjfwGeDwiRgD7U8D6qi4gImJqREzPc9NJwF0R0RwRs4EZQFrv3ANoWxO1F7Ag\npTo2djFwTUQ0A0TEkpTryfVr4N9o16KnxRERT0RES3L1ZbIrJKZlDDAjImZFxDrgLrLP+VRFxMKI\neCO53ET2xW5gulVlSRoEHA/8Ie1a2kjqBXwKuBkgItZFxPuFeryqC4jNGAjMy7k+n/SeqN8GrpU0\nj+y79NTeeW5kD+AISa9Iel7SwWkXBCDpJKAhIiakXctmnA88luLjl9LzOy9JQ4ADgFfSrWSD/yT7\npiOTdiE5hgKNwB+TU19/kFRXqAcruQWDOoKkp4Cd89x0VUQ8VOx68tlcjcDRwL9GxH2SziT7buGz\nJVBXJ6AP2VMBBwN3SxoWRfgo3BbqupLs6aWia89zTdJVZE+l3F7M2sqJpO7AfcC3I2JFCdRzArAk\nIl6XdFTa9eToBBwIfCsiXpH0G+By4IeFerCKExHb8mLaAAzOuT4oGSuIzdUo6b/InvsEuIciHuJu\noa6LgfuTQHhVUobsfDCNadUlaV+y76omSILsf7c3JI2JiEVp1ZVT378AJwBHFyNIN6Ooz++tIakz\n2XC4PSLuT7uexGHAiZKOA7YDekq6LSK+nHJd84H5EdF2lHUv2YAoCJ9i+sBY4GxJXSUNBYYDr6ZU\nywLgyOTyZ4C3U6pjYw8CnwaQtAfQhZQnMYuIiRGxU0QMiYghZP8HOrAY4bAlko4le4rixIhYnXI5\nrwHDJQ2V1IXsBzLGplwTyqb6zcDUiPhV2vW0iYgrImJQ8pw6G3imBMKB5Hk9T9KeydDRwJRCPV5F\nHkFsjqRTgN8C9cAjksZHxDERMVnS3WT/2C3AJRHRmlKZXwN+I6kTsBa4MKU6NnYLcIukScA64LyU\n3xWXuuuArsCTydHNyxFxURqFRESLpG8CfwNqgVsiYnIatWzkMOBcYKKk8cnYlcna9Jbft4Dbk6Cf\nBXylUA/kb1KbmVlePsVkZmZ5OSDMzCwvB4SZmeXlgDAzs7wcEGZmlpcDwqqCpJUfc/97JQ1LLs/p\niBljJf2LpOvasd2PJX1vC9t8U9L5H7cms1wOCLMtkDQSqI2IWWnXshm3kP18vFmHcUBYVVHWtZIm\nSZoo6axkvEbSDckc+09KelTS6cluXwLyzuEl6UFJrydrGVyYM74yeZzJkp6SNEbSc5JmSTox5y4G\nJ+NvS/pRzv5XSXpL0ovAnjnjX5P0mqQJku6TtD1A8k3tOSqhtUOs/DkgrNqcCowiO4/+Z8nOmts/\nGR9Cdq2Ec4HcRVgOA17fxP2dHxEHAaOBSyXtmIzXkZ2eYSTQBPwU+BxwCvC/c/YfA5wG7AecIWm0\npIPITu8wCjiO7MSIbe6PiIMjom0dgAtybhsHHNHOv4PZFlXdVBtW9Q4H7kymUVks6XmyL8CHA/dE\nRAZYJOnZnH36s+kJCS9Npm+B7GR4w4FlZKcieTwZnwg0R8R6SRPJBlGbJyNiGYCk+5M6AB5om79J\nUu6cSftI+inQG+hOduqMNkuAEe34G5i1iwPCbMvWkJ3R80OSaaA/CxwaEaslPZez3fqceaoyQNsi\nS5lkjq02G891E4A2U8ufgJMjYkIyU+xRObdtl9Rq1iF8ismqzX8DZym71nA92dW5XgVeAk5LehH9\n+PAL71Rg9zz31Qt4LwmHEWTXydhan5PUR1I34OSkjheAkyV1k9QD+Kec7XsAC5Mpsr+00X3tQXZJ\nXbMO4SMIqzYPkO0vTCD7bv3fImKRpPv4YOrkecAbwPJkn0fIBsZTG93X48BFkqYC08kuK7q1XiW7\nFsIg4LaIGAcg6S9JjUvITtXd5odkV1xrTH73yLntMODH21CDWV6ezdUsIal7RKxMGs2vAocl4dEN\neDa5ntYU8Jsl6QDgOxFxbtq1WOXwEYTZBx6W1JvsQkj/p23RoYhYk3wEdSDwTpoFbkZfCrTspFUv\nH0GYmVleblKbmVleDggzM8vLAWFmZnk5IMzMLC8HhJmZ5eWAMDOzvP4/ltslPtLIixMAAAAASUVO\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1160a8128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The minimum loss is 0.07000444185776974 at lambda = 1e-05\n"
     ]
    }
   ],
   "source": [
    "plt.plot(range(-10, 7), losses)\n",
    "plt.xlabel('log(lambda)')\n",
    "plt.ylabel('loss')\n",
    "plt.show()\n",
    "min_loss = min(losses)\n",
    "min_loss_lambda = range(-10, 7)[losses.index(min_loss)]\n",
    "print(\"The minimum loss is {} at lambda = {}\".format(min_loss, 10 ** min_loss_lambda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-10</th>\n",
       "      <th>-9</th>\n",
       "      <th>-8</th>\n",
       "      <th>-7</th>\n",
       "      <th>-6</th>\n",
       "      <th>-5</th>\n",
       "      <th>-4</th>\n",
       "      <th>-3</th>\n",
       "      <th>-2</th>\n",
       "      <th>-1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10e-3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10e-2</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10e-1</th>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       -10  -9   -8   -7   -6   -5   -4   -3   -2   -1    0    1    2    3   \\\n",
       "10e-3    1    1    1    1    1    0    0    0    0    0    0    0    0    0   \n",
       "10e-2    4    4    4    4    4    2    4    1    0    1    0    0    0   75   \n",
       "10e-1   23   23   23   23   23   25   21   10   11    7    1    0   75   75   \n",
       "\n",
       "        4    5    6   \n",
       "10e-3   75   75   75  \n",
       "10e-2   75   75   75  \n",
       "10e-1   75   75   75  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sparsity = pd.DataFrame(spa, index=range(-10, 7), columns=['1e-3', '1e-2', '1e-1'])\n",
    "sparsity.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from above chart, when using a threshold of $10^{-3}$, most of the true-zero coefficients are treated as non-zero; When $\\lambda=10^{-5}$, with threshold $10^{-2}$, there are only 2 zero coefficients, and 25 zero coefficents with threshold $10^{-1}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Coordinate Descent for Lasso\n",
    "\n",
    "The Lasso optimization problem can be formulated as \n",
    "$$\n",
    "\\hat{w} = \\text{argmin}_{w\\in{\\mathcal{R}^d}}\\sum_{i=1}^{n}(h_w(x_i)-y_i)^2+\\lambda\\lVert{w}\\rVert_1\n",
    "$$\n",
    "where $h_w(x) = w^Tx$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since L-1 regularization term in the objective function \n",
    "is non-differentiable, it's not clear how gradient descent or SGD\n",
    "could be used to solve this optimization problem. (In fact, subgradient will work and we will see in another notebook.)\n",
    "\n",
    "Coordinate descent is another approach to solving optimization problems, in which at each step we optimize over only one component of the unknown parameter vector, fixing all other components. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that for the Lasso optimization problem, we can find a closed form solution for optimization over a single component fixing all other components, and this gives us the following algorithm, known as the **shooting algorithm** (Murphy, Kevin P. Machine Learning: a probabilistic perspective. MIT press 2012):\n",
    "\n",
    "### 2.1 Shooting Algorithm\n",
    "---\n",
    "\n",
    "$\\begin{align*}\n",
    "&\\text{initialize } w = (X^TX+\\lambda{I})^{-1}X^Ty;\\\\\n",
    "&\\text{repeat}\\\\\n",
    "&~~~~~~\\text{for } j=1,...,D \\text{ do}\\\\\n",
    "&~~~~~~~~~~~~ a_j = 2\\sum x_{ij}^2;\\\\\n",
    "&~~~~~~~~~~~~ c_j = 2\\sum x_{ij}(y_i-w^Tx_i + w_jx_{ij});\\\\\n",
    "&~~~~~~~~~~~~ w_j = soft(\\frac{c_j}{a_j}, \\frac{\\lambda}{a_j});\\\\\n",
    "&\\text{until } converged;\\\\\n",
    "\\end{align*}$\n",
    "\n",
    "---\n",
    "\n",
    "where the _soft thresholding_ function is defined as\n",
    "\n",
    "$$soft(\\alpha, \\delta) = \\text{sign}(a)(\\lvert{a}\\rvert-\\delta)_{+}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Derive the Coordinate Minimizer for Lasso\n",
    "\n",
    "In each step of the shooting algorithm, we would like to find the $w_j$ that minimize\n",
    "\n",
    "$$\\begin{align*}\n",
    "f(w_j) &= \\sum_{i=1}^{n}(w^Tx_i - y_i)^2 + \\lambda\\lvert{w}\\rvert_1\\\\\n",
    "&= \\sum_{i=1}^n{\\left[w_jx_{ij}+\\sum_{k\\neq{j}}w_kx_{ik}-y_i\\right]^2} + \\lambda\\lvert{w_j}\\rvert+\\lambda\\sum_{k\\neq{j}}\\lvert{w_k}\\rvert\n",
    "\\end{align*}$$\n",
    "\n",
    "where $x_{ij}$ is the $j$-th entry of the vector $x_i$. \n",
    "\n",
    "1. For a zero feature, i.e. $x_{ij}=0, i=1,...,n$, the coordinate minimizer $w_j$ is derived by:  \n",
    "    $$f(w_j)=\\sum_{i=1}^n{y_i^2}+\\lambda\\lvert{w_j}\\rvert+\\lambda\\sum_{k\\neq{j}}\\lvert{w_k}\\rvert$$\n",
    "    obviously, $w_j=0$ is the coordinate minimizer.\n",
    "    $$ $$\n",
    "    \n",
    "2. When $w_j\\neq0$, the derivative of $f(w_j)$ for $w_j$ is  \n",
    "    $$\\begin{align*}f'(w_j)&=2w_j\\sum_i{x_{ij}^2}+2\\sum_{i}{x_{ij}\\left(\\sum_{k\\neq{j}}w_kx_{ik}-y_i\\right)}+\\text{sign}(w_j)\\lambda\\\\&=\\begin{cases}a_jw_j-c_j+\\lambda & w_j>0\\\\a_jw_j-c_j-\\lambda&w_j<0\\end{cases}\\end{align*}$$\n",
    "    where\n",
    "    $$\\begin{align*}a_j&=2\\sum_{i}{x_{ij}^2}\\\\c_j&=2\\sum_{i}{x_{ij}(y_i-\\sum_{k\\neq{j}}{w_kx_{ik}})}\\end{align*}$$\n",
    "    therefore, the coordinate minimizer is\n",
    "    $$w_j^* = \\begin{cases}(c_j-\\lambda)/a_j&w_j>0\\\\(c_j+\\lambda)/a_j&w_j<0\\end{cases}$$\n",
    "    $$ $$\n",
    "    \n",
    "3. So what is the minimizer at $f(0)$:  \n",
    "    \n",
    "    $$\\begin{cases}f(0^+)=-c_j+\\lambda\\\\f(0^-)=-c_j-\\lambda\\end{cases}$$\n",
    "    \n",
    "    when $c_j\\in[-\\lambda,\\lambda]$, we have $f(0^+)\\geq0$ and $f(0^-)\\leq0$, which means that $w_j=0$ is the minimizer at $f(0)$.\n",
    "    \n",
    "4. In conclusion,  \n",
    "    \n",
    "    $$\n",
    "    w_j = \\begin{cases}(c_j-\\lambda)/a_j&c_j>\\lambda\\\\\n",
    "    0&c_j\\in[-\\lambda,\\lambda]\\\\\n",
    "    (c_j+\\lambda)/a_j&c_j<-\\lambda\\end{cases}\n",
    "    $$\n",
    "    \n",
    "    which is exactly the update of $w_j$ in shooting algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shooting_algo(X, y, w, Lambda, tolerance=1e-8, max_iter=10000): \n",
    "    # input w is the starting point\n",
    "    num_instance, num_features = X.shape[0], X.shape[1]\n",
    "    converged = False\n",
    "    num_iter = 0\n",
    "    \n",
    "    while (~converged)*(num_iter < max_iter):\n",
    "        w_last = w.copy()\n",
    "        for j in range(num_features):\n",
    "            aj = 0\n",
    "            cj = 0\n",
    "            for k in range(num_instance):\n",
    "                aj += X[k,j]**2\n",
    "                cj += X[k,j] * (y[k] - np.dot(w, X[k]) + w[j] * X[k,j])\n",
    "            aj *= 2\n",
    "            cj *= 2\n",
    "            \n",
    "            # soft function\n",
    "            if (cj < -Lambda):\n",
    "                w[j] = (cj + Lambda) / aj\n",
    "            elif (cj > Lambda):\n",
    "                w[j] = (cj - Lambda) / aj\n",
    "            else:\n",
    "                w[j] = 0\n",
    "                \n",
    "        num_iter += 1\n",
    "        converged = (np.linalg.norm(w-w_last)) < tolerance\n",
    "    print(\"\\nIter number:\", num_iter)    \n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def soft(a, delta):\n",
    "    var_1 = abs(a) - delta\n",
    "    var_2 = np.max([var_1, 0.])\n",
    "    var_3 = np.sign(a)*var_2\n",
    "    return var_3\n",
    "\n",
    "def compute_square_loss(X, y, theta):\n",
    "    loss = 0\n",
    "    m = X.shape[0]\n",
    "    vector = np.dot(X, theta) - y\n",
    "    loss = float(np.dot(vector, vector))/(2*m)\n",
    "    return loss\n",
    "\n",
    "def Lasso_Shooting(X, y, theta_0, lambda_reg = 1., num_iter = 1000):\n",
    "    theta = np.zeros(theta_0.shape)\n",
    "    theta[0: len(theta)] = theta_0\n",
    "    d = X.shape[1]\n",
    "    times = 0\n",
    "    loss = compute_square_loss(X, y, theta)\n",
    "    loss_change = 1.\n",
    "    while (loss_change>1e-6) and (times<num_iter):\n",
    "        loss_old = loss\n",
    "        for j in range(d):\n",
    "            X_d = X[:, j]\n",
    "            a = np.dot(X_d.T, X_d)*2\n",
    "            vector = y - np.dot(X, theta.T) + X_d*theta[j]\n",
    "            c = np.dot(X_d.T, vector)*2\n",
    "            theta[j] = soft(c/a, lambda_reg/a)\n",
    "        times +=1\n",
    "        loss = compute_square_loss(X, y, theta)\n",
    "        loss_change = abs(loss - loss_old)\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Lasso:\n",
      "General shooting complete regularization path using 2.8884 seconds\n",
      "When Lambda = 0.01 the test loss is minimized to 0.04433416874169243\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEOCAYAAACTqoDjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1160a88d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Lasso shooting\n",
    "start_1 = time.time()\n",
    "print(\"\\n\\nLasso:\")\n",
    "# pre-search\n",
    "Lambda_set = np.array([1e-6,1e-5,1e-4,1e-3,1e-2,1e-1,1,10,100,1000,10000,100000])\n",
    "# zoom-in\n",
    "# Lambda_set = np.array([1e-6,1e-5,1e-4,3e-4,5e-4,7e-4,9e-4,1e-3,3e-3,5e-3,7e-3,1e-2,2e-2,3e-2,5e-2,7e-2,1e-1])\n",
    "loss_result = np.zeros(Lambda_set.shape)\n",
    "sparsity = []\n",
    "for i in range(Lambda_set.shape[0]):\n",
    "    # Lambda = 10**i\n",
    "    Lambda = Lambda_set[i]\n",
    "    # initialize with ridge estimator\n",
    "    w_init = np.dot(np.linalg.inv(np.dot(X_train.T, X_train) + Lambda * np.eye(X_train.shape[1])), np.dot(X_train.T, y_train))\n",
    "    w = Lasso_Shooting(X_train, y_train, w_init, Lambda)\n",
    "    loss_result[i] = compute_loss(X_valid, y_valid, Lambda, w)\n",
    "    sparsity.append(compute_sparsity(w))\n",
    "end_1 = time.time()\n",
    "print(\"General shooting completes regularization path using %.4f seconds\" % (end_1-start_1))\n",
    "print(\"When Lambda = {} the test loss is minimized to {}\".format(Lambda_set[loss_result.argmin()], min_loss))\n",
    "plt.plot(Lambda_set, loss_result)\n",
    "plt.xscale('log')\n",
    "plt.xlabel('lambda')\n",
    "plt.ylabel('loss on validation set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1e-06</th>\n",
       "      <th>1e-05</th>\n",
       "      <th>0.0001</th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.1</th>\n",
       "      <th>1.0</th>\n",
       "      <th>10.0</th>\n",
       "      <th>100.0</th>\n",
       "      <th>1000.0</th>\n",
       "      <th>10000.0</th>\n",
       "      <th>100000.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1e-3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>61</td>\n",
       "      <td>65</td>\n",
       "      <td>68</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1e-2</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>62</td>\n",
       "      <td>65</td>\n",
       "      <td>68</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1e-1</th>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>31</td>\n",
       "      <td>40</td>\n",
       "      <td>36</td>\n",
       "      <td>62</td>\n",
       "      <td>65</td>\n",
       "      <td>69</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0.000001       0.000010       0.000100       0.001000       \\\n",
       "1e-3              2              1              0              0   \n",
       "1e-2              4              4              4              2   \n",
       "1e-1             23             23             23             25   \n",
       "\n",
       "      0.010000       0.100000       1.000000       10.000000      \\\n",
       "1e-3              1              5             20             61   \n",
       "1e-2              4             10             21             62   \n",
       "1e-1             31             40             36             62   \n",
       "\n",
       "      100.000000     1000.000000    10000.000000   100000.000000  \n",
       "1e-3             65             68             75             75  \n",
       "1e-2             65             68             75             75  \n",
       "1e-1             65             69             75             75  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparsity = pd.DataFrame(sparsity, index=Lambda_set, columns=['1e-3', '1e-2', '1e-1'])\n",
    "sparsity.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared with the result from ridge regression, we can see that lasso regression performs better in terms of sparsity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Homotopy method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iter number: 2\n",
      "Lambda = 100000 loss on valid set is 227.197113828\n",
      "\n",
      "Iter number: 1\n",
      "Lambda = 10000.0 loss on valid set is 227.197113828\n",
      "\n",
      "Iter number: 96\n",
      "Lambda = 1000.0 loss on valid set is 108.026536494\n",
      "\n",
      "Iter number: 157\n",
      "Lambda = 100.0 loss on valid set is 24.7004609486\n",
      "\n",
      "Iter number: 291\n",
      "Lambda = 10.0 loss on valid set is 0.562014505656\n",
      "\n",
      "Iter number: 841\n",
      "Lambda = 1.0 loss on valid set is 0.0131818373821\n",
      "\n",
      "Iter number: 2118\n",
      "Lambda = 0.1 loss on valid set is 0.0124196948372\n",
      "\n",
      "Iter number: 4313\n",
      "Lambda = 0.01 loss on valid set is 0.0383524441931\n",
      "\n",
      "Iter number: 4082\n",
      "Lambda = 0.001 loss on valid set is 0.0698360114423\n",
      "\n",
      "Iter number: 2265\n",
      "Lambda = 0.0001 loss on valid set is 0.0776610368443\n",
      "\n",
      "Iter number: 119\n",
      "Lambda = 1e-05 loss on valid set is 0.0777442704541\n",
      "\n",
      "Iter number: 20\n",
      "Lambda = 1.0000000000000002e-06 loss on valid set is 0.0777522538926\n",
      "Homotopy complete regularization path using 227.07992005348206\n",
      "When Lambda = [ 1.] the test loss is minimized as 0.0124196948372\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEOCAYAAACTqoDjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSEYKCBERyUgBISIiGSkgREQko/8P739N7Tigj3UAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1165bf550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# homotopy method \n",
    "start_2 = time.time()\n",
    "#Lambda_set = np.array([1e-6,1e-5,1e-4,1e-3,1e-2,1e-1,1,10])\n",
    "loss_result = np.zeros(Lambda_set.shape)\n",
    "sparsity = []\n",
    "Lambda = 10**5\n",
    "w = np.dot(np.linalg.inv(np.dot(X_train.T, X_train) + Lambda * np.eye(X_train.shape[1])), np.dot(X_train.T, y_train))\n",
    "    \n",
    "for i in range(Lambda_set.shape[0]):\n",
    "    # warm start\n",
    "    w = shooting_algo(X_train, y_train, w, Lambda, tolerance=1e-5)\n",
    "    loss_result[i] = compute_loss(X_valid, y_valid, Lambda, w)\n",
    "    print(\"Lambda =\", Lambda, \"loss on valid set is\", loss_result[i])\n",
    "#     report_sparsity(theta, w)\n",
    "    sparsity.append(compute_sparsity(w))\n",
    "    Lambda = Lambda / 10\n",
    "    \n",
    "end_2 = time.time()\n",
    "print(\"Homotopy complete regularization path using\", end_2-start_2)\n",
    "min_loss = loss_result.min()\n",
    "print(\"When Lambda =\", Lambda_set[loss_result == min_loss], \"the test loss is minimized as\", min_loss)\n",
    "plt.plot(Lambda_set, loss_result)\n",
    "plt.xscale('log')\n",
    "plt.xlabel('lambda')\n",
    "plt.ylabel('loss on validation set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iter number: 225\n",
      "Lambda = 10 loss on valid set is 0.194895889668\n",
      "Number of true-0 value treated as non-zero is 0\n",
      "When using threshold 0.001  the number of true-0 treated as non-zero is 0\n",
      "\n",
      "Iter number: 337\n",
      "Lambda = 1.0 loss on valid set is 0.00915771311589\n",
      "Number of true-0 value treated as non-zero is 7\n",
      "When using threshold 0.001  the number of true-0 treated as non-zero is 6\n",
      "\n",
      "Iter number: 2831\n",
      "Lambda = 0.1 loss on valid set is 0.0103138533958\n",
      "Number of true-0 value treated as non-zero is 46\n",
      "When using threshold 0.001  the number of true-0 treated as non-zero is 45\n",
      "\n",
      "Iter number: 2408\n",
      "Lambda = 0.01 loss on valid set is 0.0374394836143\n",
      "Number of true-0 value treated as non-zero is 59\n",
      "When using threshold 0.001  the number of true-0 treated as non-zero is 59\n",
      "\n",
      "Iter number: 3529\n",
      "Lambda = 0.001 loss on valid set is 0.0698230270798\n",
      "Number of true-0 value treated as non-zero is 65\n",
      "When using threshold 0.001  the number of true-0 treated as non-zero is 65\n",
      "\n",
      "Iter number: 1506\n",
      "Lambda = 0.0001 loss on valid set is 0.0742168272413\n",
      "Number of true-0 value treated as non-zero is 65\n",
      "When using threshold 0.001  the number of true-0 treated as non-zero is 65\n",
      "\n",
      "Iter number: 459\n",
      "Lambda = 1e-05 loss on valid set is 0.0745180188961\n",
      "Number of true-0 value treated as non-zero is 65\n",
      "When using threshold 0.001  the number of true-0 treated as non-zero is 65\n",
      "\n",
      "Iter number: 49\n",
      "Lambda = 1.0000000000000002e-06 loss on valid set is 0.0745336097992\n",
      "Number of true-0 value treated as non-zero is 65\n",
      "When using threshold 0.001  the number of true-0 treated as non-zero is 65\n",
      "Homotopy complete regularization path using 119.38971996307373\n"
     ]
    }
   ],
   "source": [
    "# homotopy method  222\n",
    "start_4 = time.time()\n",
    "Lambda_set = np.array([1e-6,1e-5,1e-4,1e-3,1e-2,1e-1,1,10])\n",
    "loss_result = np.zeros(Lambda_set.shape)\n",
    "Lambda = 10\n",
    "w = np.dot(np.linalg.inv(np.dot(X_train.T, X_train) + Lambda * np.eye(X_train.shape[1])), np.dot(X_train.T, y_train))\n",
    "    \n",
    "for i in range(Lambda_set.shape[0]):\n",
    "    # Lambda = 10**i\n",
    "    # Lambda = Lambda_set[i]\n",
    "    #w_init = np.dot(np.linalg.inv(np.dot(X_train.T, X_train) + Lambda * np.eye(X_train.shape[1])), np.dot(X_train.T, y_train))\n",
    "    #w = shooting_algo(X_train, y_train, w_init, Lambda, tolerance=1e-5)\n",
    "        \n",
    "    w = shooting_algo2(X_train, y_train, w, Lambda, tolerance=1e-5)\n",
    "    loss_result[i] = compute_loss(X_valid, y_valid, Lambda, w)\n",
    "    print(\"Lambda =\", Lambda, \"loss on valid set is\", loss_result[i])\n",
    "    report_sparsity(theta, w)\n",
    "    Lambda = Lambda / 10\n",
    "    \n",
    "end_4 = time.time()\n",
    "print(\"Homotopy complete regularization path using\", end_4-start_4)\n",
    "#min_loss = loss_result.min()\n",
    "#print(\"When Lambda =\", Lambda_set[loss_result == min_loss], \"the test loss is minimized as\", min_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Vectorization shooting\n",
    "\n",
    "The algorithm as described above is not ready for a large dataset (at least if it has been implemented in basic Python) because of the implied loop over the dataset (i.e. where we sum over the training set). By using matrix and vector operations, we can eliminate the loops. This is called “vectorization” and can lead to dramatic speedup in languages such as Python, Matlab, and R. Derive matrix expressions for computing $a_j$ and $c_j$.\n",
    "\n",
    "Now we are going to implement the matrix expressions and measure the speedup in computing the regularization path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorized_shooting(X, y, w, Lambda, tolerance=1e-8, max_iter=10000): \n",
    "    # input w is the starting point\n",
    "    \n",
    "    num_instance, num_features = X.shape[0], X.shape[1]\n",
    "    converged = False\n",
    "    num_iter = 0\n",
    "    \n",
    "    XX2 = 2 * np.dot(X.T, X)  #(num_feat * num_feat)\n",
    "    Xy2 = 2 * np.dot(X.T, y)  #(num_feat * 1)\n",
    "    \n",
    "    while (~converged):#*(num_iter < max_iter):\n",
    "        w_last = w.copy()\n",
    "        for j in range(num_features):\n",
    "            aj = XX2[j,j]\n",
    "            cj = Xy2[j] - np.dot(XX2[j], w) + XX2[j,j] * w[j]\n",
    "            \n",
    "            # soft function\n",
    "            if (cj < -Lambda):\n",
    "                w[j] = (cj + Lambda) / aj\n",
    "            elif (cj > Lambda):\n",
    "                w[j] = (cj - Lambda) / aj\n",
    "            else:\n",
    "                w[j] = 0\n",
    "                \n",
    "        num_iter += 1\n",
    "        converged = (np.linalg.norm(w-w_last)) < tolerance\n",
    "    print(\"\\nIter number:\", num_iter)    \n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iter number: 225\n",
      "Lambda = 10 loss on valid set is 0.194895889668\n",
      "Number of true-0 value treated as non-zero is 0\n",
      "When using threshold 0.001  the number of true-0 treated as non-zero is 0\n",
      "\n",
      "Iter number: 337\n",
      "Lambda = 1.0 loss on valid set is 0.00915771311589\n",
      "Number of true-0 value treated as non-zero is 7\n",
      "When using threshold 0.001  the number of true-0 treated as non-zero is 6\n",
      "\n",
      "Iter number: 2831\n",
      "Lambda = 0.1 loss on valid set is 0.0103138533958\n",
      "Number of true-0 value treated as non-zero is 46\n",
      "When using threshold 0.001  the number of true-0 treated as non-zero is 45\n",
      "\n",
      "Iter number: 2408\n",
      "Lambda = 0.01 loss on valid set is 0.0374394836143\n",
      "Number of true-0 value treated as non-zero is 59\n",
      "When using threshold 0.001  the number of true-0 treated as non-zero is 59\n",
      "\n",
      "Iter number: 3529\n",
      "Lambda = 0.001 loss on valid set is 0.0698230270798\n",
      "Number of true-0 value treated as non-zero is 65\n",
      "When using threshold 0.001  the number of true-0 treated as non-zero is 65\n",
      "\n",
      "Iter number: 1506\n",
      "Lambda = 0.0001 loss on valid set is 0.0742168272413\n",
      "Number of true-0 value treated as non-zero is 65\n",
      "When using threshold 0.001  the number of true-0 treated as non-zero is 65\n",
      "\n",
      "Iter number: 459\n",
      "Lambda = 1e-05 loss on valid set is 0.0745180188961\n",
      "Number of true-0 value treated as non-zero is 65\n",
      "When using threshold 0.001  the number of true-0 treated as non-zero is 65\n",
      "\n",
      "Iter number: 49\n",
      "Lambda = 1.0000000000000002e-06 loss on valid set is 0.0745336097992\n",
      "Number of true-0 value treated as non-zero is 65\n",
      "When using threshold 0.001  the number of true-0 treated as non-zero is 65\n",
      "Vectorization shooting complete regularization path using 1.9114530086517334\n",
      "When Lambda = [  1.00000000e-05] the test loss is minimized as 0.00915771311589\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEOCAYAAACjJpHCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10ef24278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# vectorization shooting \n",
    "start_3 = time.time()\n",
    "Lambda_set = np.array([1e-6,1e-5,1e-4,1e-3,1e-2,1e-1,1,10])\n",
    "loss_result = np.zeros(Lambda_set.shape)\n",
    "Lambda = 10\n",
    "w = np.dot(np.linalg.inv(np.dot(X_train.T, X_train) + Lambda * np.eye(X_train.shape[1])), np.dot(X_train.T, y_train))\n",
    "    \n",
    "for i in range(Lambda_set.shape[0]):\n",
    "    \n",
    "    w = vectorized_shooting(X_train, y_train, w, Lambda, tolerance=1e-5)\n",
    "    loss_result[i] = compute_loss(X_valid, y_valid, Lambda, w)\n",
    "    print(\"Lambda =\", Lambda, \"loss on valid set is\", loss_result[i])\n",
    "    report_sparsity(theta, w)\n",
    "    Lambda = Lambda / 10\n",
    "    \n",
    "end_3 = time.time()\n",
    "print(\"Vectorization shooting complete regularization path using\", end_3-start_3)\n",
    "min_loss = loss_result.min()\n",
    "print(\"When Lambda =\", Lambda_set[loss_result == min_loss], \"the test loss is minimized as\", min_loss)\n",
    "plt.plot(Lambda_set, loss_result)\n",
    "plt.xscale('log')\n",
    "plt.xlabel('lambda')\n",
    "plt.ylabel('loss on validation set')\n",
    "plt.savefig('./output/vector_homotopy_shooting.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original correlation of x1 and x2: -0.162376443064\n",
      "With highly correlated x1 and x2: 0.999505988474\n",
      "\n",
      "Lambda = 1000\n",
      "\n",
      "Iter number: 2\n",
      "w of ridge: [-0.00179213 -0.0017954 ] ridge loss = 82.0013896428\n",
      "w of lasso: [ 0.  0.] lasso loss = 82.7096272087\n",
      "\n",
      "Lambda = 100.0\n",
      "\n",
      "Iter number: 709\n",
      "w of ridge: [-0.01614024 -0.01617011] ridge loss = 76.4335761698\n",
      "w of lasso: [ 0.          2.37954114] lasso loss = 19.035957404\n",
      "\n",
      "Lambda = 10.0\n",
      "\n",
      "Iter number: 2961\n",
      "w of ridge: [-0.06950648 -0.06965893] ridge loss = 54.7666507963\n",
      "w of lasso: [ 9.07842686  0.        ] lasso loss = 5.36615958154\n",
      "\n",
      "Lambda = 1.0\n",
      "\n",
      "Iter number: 39951\n",
      "w of ridge: [ 0.21839852  0.21832801] ridge loss = 43.1467722037\n",
      "w of lasso: [ 10.4101305    0.92175515] lasso loss = 8.78162481291\n",
      "\n",
      "Lambda = 0.1\n",
      "\n",
      "Iter number: 4957\n",
      "w of ridge: [ 2.00439005  2.00362686] ridge loss = 32.9580107991\n",
      "w of lasso: [ 12.12264366   0.        ] lasso loss = 23.0268520445\n"
     ]
    }
   ],
   "source": [
    "# test of repeated features\n",
    "#print(X_train[:,0])\n",
    "#print(X_train[:,1])\n",
    "\n",
    "X_corr = X_train.copy()\n",
    "y_corr = y_train.copy()\n",
    "print(\"Original correlation of x1 and x2:\", np.corrcoef(X_corr[:,0],X_corr[:,1])[0][1])\n",
    "\n",
    "X_corr[:,1] = X_corr[:,0] + 1e-2 * np.random.randn(X_corr[:,0].shape[0])\n",
    "print(\"With highly correlated x1 and x2:\", np.corrcoef(X_corr[:,0],X_corr[:,1])[0][1])\n",
    "X_covalid = X_valid.copy()\n",
    "y_covalid = y_valid.copy()\n",
    "\n",
    "X_covalid[:,1] = X_covalid[:,0] + 1e-2 * np.random.randn(X_covalid[:,0].shape[0])\n",
    "\n",
    "Lambda = 1000\n",
    "# init w for lasso regression\n",
    "w_lasso = np.dot(np.linalg.inv(np.dot(X_corr.T, X_corr) + Lambda * np.eye(X_corr.shape[1])), np.dot(X_corr.T, y_corr))\n",
    "\n",
    "for i in range(5):\n",
    "    print(\"\\nLambda =\", Lambda)\n",
    "    \n",
    "    # init w for ridge regression\n",
    "    w = np.random.rand(X_corr.shape[1],1)\n",
    "    w_r = minimize(ridge(X_corr, y_corr, Lambda), w)\n",
    "    w_ridge = w_r.x\n",
    "    loss_ridge = compute_loss(X_covalid, y_covalid, Lambda=Lambda, theta=w_ridge)\n",
    "    \n",
    "    w_lasso = vectorized_shooting(X_corr, y_corr, w_lasso, Lambda, tolerance=1e-5)\n",
    "    loss_lasso = compute_loss(X_covalid, y_covalid, Lambda=Lambda, theta=w_lasso)\n",
    "    print(\"w of ridge:\", w_ridge[:2], \"ridge loss =\", loss_ridge)\n",
    "    print(\"w of lasso:\", w_lasso[:2], \"lasso loss =\", loss_lasso)\n",
    "    Lambda /= 10 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
